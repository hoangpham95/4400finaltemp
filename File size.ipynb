{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_dir = '/home/hoang/Downloads/train/'\n",
    "files = [f for f in listdir(train_dir) if isfile(join(train_dir, f))]\n",
    "\n",
    "class CSVProcessor:\n",
    "    def __init__(self, fdir, fname):\n",
    "        self.fdir = fdir\n",
    "        self.fname = fname\n",
    "        \n",
    "    def process(self):\n",
    "        line = 0\n",
    "        df = pd.read_csv(filepath_or_buffer=os.path.join(self.fdir, self.fname))\n",
    "        return df\n",
    "    \n",
    "proc = CSVProcessor('data/', 'trainLabels.csv')\n",
    "df = proc.process()\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.8, random_state=42) # train on 40% given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hashes = [x for x in train['Id']]\n",
    "train_classes = [x for x in train['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDf:\n",
    "    def __init__(self, data):\n",
    "        self.hashes = [x for x in data['Id']]\n",
    "        self.classes = [x for x in data['Class']]\n",
    "        \n",
    "    def get_df(self):\n",
    "        df = pd.DataFrame(columns=['hashes', 'asm', 'bytes', 'class'])\n",
    "        df['hashes'] = self.hashes\n",
    "        df['class'] = self.classes\n",
    "        df['asm'] = [os.stat(join(train_dir, f + '.asm')).st_size for f in self.hashes]\n",
    "        df['bytes'] = [os.stat(join(train_dir, f + '.bytes')).st_size for f in self.hashes]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[['asm', 'bytes']])\n",
    "        df[['asm', 'bytes']] = scaler.transform(df[['asm', 'bytes']])\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rdc = RandomForestClassifier(n_estimators=400, max_depth=int(np.sqrt(2173)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = GetDf(train).get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2173, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/Documents/school/4400/env/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=46, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdc.fit(train_df[['asm', 'bytes']], train_df[['class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    hashes       asm     bytes  class\n",
      "0     E4lBhCXvziDf2rU3GM7t -0.553289  1.011585      3\n",
      "1     k0DVI4svgBRA8pjlf9M1 -0.375412 -0.945791      1\n",
      "2     c64G93TVZM258AUDSCka -0.356998 -1.005105      2\n",
      "3     cpdsREmet3FyD1oYZVIn -0.557265  1.011585      3\n",
      "4     283STBsQaI7Pw9qf0tjy -0.524947 -1.139551      2\n",
      "5     CW6cHidJb35VTMQ0jms7 -0.557271  1.011585      3\n",
      "6     BAGfw1SeoPIqyhTErbit -0.432004 -1.100008      4\n",
      "7     6kgpyCID8l4Pw7BYHTjM -0.389260 -1.060465      8\n",
      "8     gGbvOKAXCB5047PEf6aS -0.467810 -1.076282      1\n",
      "9     F3Zj217CLRxgi0NyHMY4 -0.497485 -1.076282      1\n",
      "10    FSqi0ZaPveb5jMxtBcfs -0.230800 -1.032785      9\n",
      "11    Agr9Oh1eLIP0QCpRNkUt  0.879685  1.011585      3\n",
      "12    GkA3vhfoHbwdeKPBl4ZR -0.239741 -1.032785      9\n",
      "13    kGITL4OJxYMWEQ1bKBiP  0.326556 -0.408007      9\n",
      "14    fgD5k647jbdSEWBZCQnh -0.557277  1.015539      3\n",
      "15    ic1gqvXzQFDjZ5YxkmSt -0.556988  1.766855      3\n",
      "16    blhHt3mGR6pFC0Or41SL -0.557053  1.766855      3\n",
      "17    BC9hzqbTa0OIsePYiND6  1.985183  0.193046      9\n",
      "18    7ED0sQObTcBd6kL8IwJU -0.110682 -0.799482      2\n",
      "19    4ac5qdOrj96X8SglAGZL -0.510921 -1.084191      9\n",
      "20    30Sj9rlHUZveV8FN1k54 -0.003452  0.501481      2\n",
      "21    dsuIp14XKzEt6kU29yeV -0.560274 -0.107480      1\n",
      "22    7UEqLpy8zmkvfA2e5Nob -0.370188 -1.060465      8\n",
      "23    4UblA5oWqLNmdVF8sDw0 -0.511465 -1.088145      9\n",
      "24    0fxgjYEClPL1BDbcshzJ -0.556941  1.766855      3\n",
      "25    d7czUVqJApx6WEj4ownT -0.518970 -1.096054      6\n",
      "26    ceyIk4f0BRUiar5bLJ8l -0.556261  1.766855      3\n",
      "27    7HAqkJSVFhjle8tn412s -0.557862  1.011585      3\n",
      "28    hfou5GTCL1HKIYcUEp0q  0.403943 -0.684807      6\n",
      "29    9EbqOQ5sCRtSVzg3DyMn -0.557916  1.011585      3\n",
      "...                    ...       ...       ...    ...\n",
      "8665  I6zJbjtT7gxKcwVWf29C -0.557250  1.011585      3\n",
      "8666  5bOucF2zs3YnAgZEp9BC -0.555297  1.766855      3\n",
      "8667  hUc3sa5YXmb2EoZ1pGrD  2.473256  0.647790      2\n",
      "8668  508Uk9z1gvCtucARFWG3 -0.075031 -0.629447      4\n",
      "8669  bKRFqsMCtGHNh13fw6od -0.187992  0.030920      9\n",
      "8670  BiZV7jR96sXH4IhbrLNJ  0.131581 -0.518727      1\n",
      "8671  HaI3lhUAXN6Qv0jW9FMg -0.557257  1.011585      3\n",
      "8672  27V4S1ncC3fj0gitGuDI -0.477053 -1.032785      6\n",
      "8673  FfxBsCDyAul0HSgtGdM1 -0.512914 -1.088145      9\n",
      "8674  CV7DFk6tUNpbyJcwEKsx -0.074834 -0.629447      4\n",
      "8675  1sOzen4EwI3a2UkSJmT5 -0.520187 -1.127688      8\n",
      "8676  8WOdj5swHa1A204fNyU6 -0.334852 -0.700624      6\n",
      "8677  hpKeXGQLyJzdtmO9u1MR -0.188822  0.030920      9\n",
      "8678  8JqbzxWR216yr3Ptgems -0.557289  1.011585      3\n",
      "8679  EiD3lRHWhCw4zY9SjXVI -0.521161 -1.127688      8\n",
      "8680  bSRakDIeOuFoq7NHQP3j -0.558681  1.015539      3\n",
      "8681  6PG57gUmE2rLebCBTMno -0.073019 -0.625493      4\n",
      "8682  7sbEMLcRn1mktlNwzdxW  1.102770 -0.113882      2\n",
      "8683  Bu6mavPcgfkURx4Fp8LY -0.560510 -1.119780      1\n",
      "8684  Av2JeYcnT9E5GxQ81XBN  0.617956 -0.593859      2\n",
      "8685  BSNsRxEFa4YU6Ov1iq2I -0.416925 -1.084191      4\n",
      "8686  GLzSZuahXjcxv4fQPosm -0.553444  1.011585      3\n",
      "8687  9As0CbJPKyq8MFgmNcl7 -0.555272  1.766855      3\n",
      "8688  ERxv2Sm37oVrpwNdThsk -0.553265  1.011585      3\n",
      "8689  5itrSmMjzBwOvcb7JgZe -0.557290  1.011585      3\n",
      "8690  dwIXmJU36HYyvpC8hj2n -0.557250  1.011585      3\n",
      "8691  45aTQcuSVrGxZ62vHLbw -0.291768 -1.092100      6\n",
      "8692  adHqeXxjBJVt9KD7obTZ -0.536951 -1.103962      1\n",
      "8693  kLPUQYKrA1jGsJdtS0bf  0.200892  1.252797      2\n",
      "8694  D0NQOcIT94lrkWxzyaP6 -0.515297 -1.084191      9\n",
      "\n",
      "[8695 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5709028177113283"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_df = GetDf(test).get_df()\n",
    "print(test_df)\n",
    "accuracy_score(rdc.predict(test_df[['asm', 'bytes']]), test_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7).fit(train_df[['asm', 'bytes']], train_df[['class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(test_df[['asm', 'bytes']], test_df[['class']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=10), n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.fit(train_df[['asm', 'bytes']], train_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.score(test_df[['asm', 'bytes']], test_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10)\n",
    "dtc.fit(train_df[['asm', 'bytes']], train_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.score(test_df[['asm', 'bytes']], test_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
